#!/usr/bin/python


# Imports.
import os
import os.path
import tempfile
import urlparse
import re
import ConfigParser
import shutil
import ligo.gracedb.rest

from sys             import exit, stdin
from workflow_helper import directory, home
from glue.ligolw     import ligolw
from glue.ligolw     import utils
from glue.ligolw     import table
from glue.ligolw     import lsctables
from ligo.lvalert.utils import get_LVAdata_from_stdin


# Create a dictionary from the gracedb table.
streamdata = get_LVAdata_from_stdin(stdin, as_dict=True)


# Read lowmass_config.ini.
cp = ConfigParser.ConfigParser()
etc = home + '/opt/etc/'
cp.read( etc + 'lowmass_config.ini' )

#dqwaitscript       = cp.get('executable', 'dqwaitscript')
#dqtolabelscript    = cp.get('executable', 'dqtolabelscript')
#coincdetscript     = cp.get('executable', 'coincdetscript')
gracedbcommand     = cp.get('executable', 'gracedbcommand')
coinc_search       = cp.get('executable', 'coincscript')
#vetodefinerfile    = cp.get('veto', 'vetodefinerfile')


# Build and move to a unique working directory.
working = directory(streamdata['uid'])
working.build_and_move()
wdir = working.name


## Check if the incoming event is new.
#if streamdata['alert_type'] == 'new':
#    pass
# Avoid race conditions by demanding that the file 'psd.xml.gz' exist before proceeding.
if streamdata['alert_type'] == 'update' and streamdata['file'] == 'psd.xml.gz':
	pass

# If the update is a .fits file, plot the all-sky map it contains.
elif streamdata['alert_type'] == 'update' and streamdata['file'].contains('.fits'):
	fitsfile = streamdata['file']

	# Write plot_allsky.sub.
	contents = """\
universe            = vanilla

executable          = /usr/bin/env
arguments           = " bayestar_plot_allsky -o %(directory)s/%(fits)s.png --contour=50 --contour=90 --figure-width=12 --figure-height=9 %(directory)s/%(fits)s "
getenv              = True
notification        = never

error               = %(directory)s/allsky_%(uid)s.err
output              = %(directory)s/allsky_%(uid)s.out

+LVAlertListen      = %(uid)s_plot_allsky

Queue
"""
	with open('plot_allsky.sub', 'w') as f:
		f.write(contents%{'fits':fitsfile, 'directory':wdir, 'uid':streamdata['uid']})

	# Write coinc_search.sub.
	contents = """\
universe            = vanilla

executable          = %(script)s
arguments           = " --graceid=%(uid)s --direction=backward "
getenv              = True
notification        = never

output              = %(directory)s/coinc_search_%(uid)s.out
error               = %(directory)s/coinc_search_%(uid)s.error

+LVAlertListen      = %(uid)s_coinc_search

Queue
"""
	with open('coinc_search.sub', 'w') as f:
		f.write(contents%{'script': coinc_search, 'directory': wdir, 'uid': streamdata['uid']})


	# Write and submit fits_followup.dag.
	contents = """\
JOB PLOTALLSKY plot_allsky.sub
SCRIPT PRE PLOTALLSKY %(gracedbcommand)s download %(uid)s %(fits)s
SCRIPT POST PLOTALLSKY %(gracedbcommand)s --tag-name=sky_loc upload %(uid)s %(fits)s.png

JOB COINCSEARCH coinc_search.sub
"""
	with open('fits_followup.dag', 'w') as f:
		f.write(contents % {'gracedbcommand': gracedbcommand, 'uid': streamdata['uid'], 'fits': fitsfile},)

	# Create a uniquely-named log file.
	logfid, logpath = tempfile.mkstemp(suffix='.nodes.log', prefix=streamdata['uid'])

	# Set environment variable telling condor to use this log file
	# for communication with nodes.
	os.environ['_CONDOR_DAGMAN_DEFAULT_NODE_LOG'] = logpath

	# Submit the processor dag.
	condorargs=['condor_submit_dag','fits_followup.dag']
	os.execlp('condor_submit_dag', *condorargs)

# Elsewise, end the processor.
else:
	 exit()

# Extract information about the event.
coincfile = 'coinc.xml'
gracedb_client = ligo.gracedb.rest.GraceDb()
remote_file = gracedb_client.files(streamdata['uid'], coincfile)

with open(coincfile, 'w') as local_file:
	shutil.copyfileobj(remote_file, local_file)

doc        = utils.load_filename(coincfile)
coinctable = table.get_table(doc,lsctables.CoincInspiralTable.tableName)


# Get ifo info.
gpstime  = coinctable[0].end_time
ifonames = ['H1','L1','V1']
if 'test' in cp.sections():
	ifos = cp.get('test','ifos')
else:
	ifos = coinctable[0].ifos

disable_ifos = [ifo for ifo in ifonames if ifo not in ifos]
itime        = str( int( float(gpstime) + 0.5 ) )


##############################
## PRODUCE CONDOR SUB FILES ##
##############################

# Write data quality.sub.
#contents   = """\
#universe            = vanilla
#
#executable          = /bin/cp
#arguments           = /home/gdb_processor/dq-fake.xml %(directory)s/dq.xml
#getenv              = True
#notification        = never
#
#output              = %(directory)s/dq_%(uid)s.out
#error               = %(directory)s/dq_%(uid)s.error
#
#+LVAlertListen      = %(uid)s_dq
#Queue
#"""
#with open('dq.sub', 'w') as f:
#	f.write(contents%{'directory': wdir, 'uid': streamdata['uid']})
#
#	f.write(contents%{'script': dqtolabelscript, 'gdbcommand': gracedbcommand, 'vetodefinerfile': vetodefinerfile, 'directory': wdir, 'uid': streamdata['uid']})
#
# Write emlabel.sub.
#contents   = """\
#universe            = vanilla
#
#executable          = %(script)s
#arguments           = " --set-em-ready -f /home/gdb_processor/dq-fake.xml -i %(uid)s -g %(gdbcommand)s --veto-definer-file %(vetodefinerfile)s "
#getenv              = True
#notification        = never
#
#error               = %(directory)s/emlabel_%(uid)s.err
#output              = %(directory)s/emlabel_%(uid)s.out
#
#+LVAlertListen      = %(uid)s_emlabel
#Queue
#"""
#with open('emlabel.sub','w') as f:
#	f.write(contents%{'script': dqtolabelscript, 'gdbcommand': gracedbcommand, 'vetodefinerfile': vetodefinerfile, 'directory': wdir, 'uid': streamdata['uid']})

# Write localize.sub.
contents   = """\
universe            = vanilla

executable          = /usr/bin/env
environment         = OMP_NUM_THREADS=1
request_memory      = 1400 MB
arguments           = " bayestar_localize_lvalert %(uid)s "
getenv              = True
notification        = never

error               = %(directory)s/localize_%(uid)s.err
output              = %(directory)s/localize_%(uid)s.out

+LVAlertListen      = %(uid)s_localize

Queue
"""
with open('localize.sub', 'w') as f:
	f.write(contents%{'directory': wdir, 'uid': streamdata['uid']})

# Write find_data.sub.
contents   = """\
universe            = vanilla

executable          = /usr/bin/env
arguments           = " find_data --padding 20 -g %(uid)s -f H1=H1_ER_C00_L1 -f L1=L1_ER_C00_L1 -f V1=V1Online -s ldr.ligo.caltech.edu:443 --verbose "
getenv              = True
notification        = never

error               = %(directory)s/find_data_%(uid)s.err
output              = %(directory)s/find_data_%(uid)s.out

+Online_CBC_EM_FOLLOWUP = True
Requirements        = TARGET.Online_CBC_EM_FOLLOWUP =?= True
+LVAlertListen      = %(uid)s_find_data

Queue
"""
with open('find_data.sub', 'w') as f:
	f.write(contents%{'directory': wdir, 'uid': streamdata['uid']})


#################################
## WRITE CONDOR DAG AND SUBMIT ##
#################################

# Write lowmass_runner.dag.
contents = """\
JOB LOCALIZE localize.sub
SCRIPT POST LOCALIZE %(gracedbcommand)s label %(uid)s EM_READY

JOB FINDDATA find_data.sub
"""
with open('lowmass_runner.dag', 'w') as f:
	f.write(contents % {'gracedbcommand': gracedbcommand, 'uid': streamdata['uid']})

# Create a uniquely-named log file.
logfid, logpath = tempfile.mkstemp(suffix='.nodes.log', prefix=streamdata['uid'])

# Set environment variable telling condor to use this log file
# for communication with nodes.
os.environ['_CONDOR_DAGMAN_DEFAULT_NODE_LOG'] = logpath

# Submit the processor dag.
condorargs=['condor_submit_dag','lowmass_runner.dag']
os.execlp('condor_submit_dag', *condorargs)
