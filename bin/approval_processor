#!/usr/bin/python
import os
import json
from sys import stdin
#from ligo.gracedb.rest import GraceDb, HTTPError
from rest import GraceDb, HTTPError
import re
import subprocess
import ConfigParser
from lal import gpstime
import operator
import functools

import logging

#--------------------------------------------------------------------------------------
# Fetch parameters
#--------------------------------------------------------------------------------------
# Import FAR threshold, iDQ threshold from config file
config = ConfigParser.SafeConfigParser()
config.read('approval_processor_config.ini')
idqthresh = config.getfloat('default', 'idqthresh')
idq_pipelines = config.get('default', 'idq_pipelines')
idq_pipelines = idq_pipelines.replace(' ','') # remove any spaces
idq_pipelines = idq_pipelines.split(',') # a list of iDQ pipelines
humanscimons = config.get('default', 'humanscimons')

# Set up logging
logging.basicConfig(filename=config.get('default', 'approval_processor_logfile'), level=logging.INFO)

#--------------------------------------------------------------------------------------
# Utilities
#--------------------------------------------------------------------------------------

# Instantiate the GraceDB client
# For testing purposes, this is pointed towards simdb.
# If we leave out the argument, it will default to https://gracedb.ligo.org/api/
try:
	#g = GraceDb('https://simdb.phys.uwm.edu/api/')
	g = GraceDb()
except Exception, e:
	logging.error('Connection to GraceDB failed: {0}'.format(str(e)))
	exit()

# A utility to get the FAR threshold given pipeline and search.
# It's probably important to have a default value just in case.
def get_farthresh(pipeline, search):
	try:
		return config.getfloat('default', 'farthresh[{0}.{1}]'.format(pipeline, search))
	except:
		return config.getfloat('default', 'default_farthresh')

# Define a function for pulling down and sending out the correct VOEvent depending on label type

def process_alert(client, graceid, voevent_type, skymap_filename=None, 
    skymap_type=None, skymap_image_filename=None):
    logging.info("Processing %s VOEvent for MDC event %s .... " % (voevent_type, graceid))

    # Create the VOEvent.
    voevent = None
    try:
        r = client.createVOEvent(graceid, voevent_type, skymap_filename=skymap_filename, 
            skymap_type=skymap_type, skymap_image_filename=skymap_image_filename)
        voevent = r.json()['text']
    except HTTPError, e:
        logging.info("Caught HTTPError: %s" % str(e))
    if voevent:
        tmpfile = open('/tmp/voevent.tmp',"w")
        tmpfile.write(voevent)
        tmpfile.close()
        # Send it out with comet!
        cmd = "comet-sendvo -p 5340 -f /tmp/voevent.tmp"
        proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        output, error = proc.communicate(voevent)
        logging.debug("output = %s" % output)
        logging.debug("error = %s" % error)

    if proc.returncode == 0:
        message = "%s VOEvent sent to GCN for testing purposes." % voevent_type
	r = g.writeLog(graceid, 'Successfully sent VOEvent of type %s' % voevent_type, None, None, 'em_follow')
    else:
        message = "Error sending %s VOEvent! %s" % (voevent_type, error)
	# XXX: Writing in the GraceDb log that we successfully sent VOEvent just for de-bugging purposes. We aren't connected to GCN yet so delete this later.
	r = g.writeLog(graceid, 'Successfully sent VOEvent of type %s' % voevent_type, None, None, 'em_follow')
    logging.debug(message)


# Define a function that checks for the human scimon signoffs
def checkSignoffs(graceid):
	log_dicts = g.logs(graceid).json()['log']
	signoffdict = {}
	for message in log_dicts:
		if 'Finished running human signoff checks.' in message['comment']:
			passorfail = re.findall(r'Candidate event (.*?)ed human signoff checks.', message['comment'])
			if passorfail[0]=='pass':
				return 'Passed human signoff checks.'
			elif passorfail[0]=='fail':
				return 'Failed human signoff checks.'
		else:
			pass 
	for detector in detectors:
		filename = 'signoff_from_{0}.txt'.format(detector)
		try:
			signofftxt = g.files(graceid, filename)
			fails = re.findall(r'Fail',signofftxt.read())
			logging.info('Got the human scimon file for {0} from {1}'.format(graceid, detector))
			if len(fails) > 0:
				signoffdict[detector] = 'Fail'
			else:
				signoffdict[detector] = 'Pass'
		except Exception, e:
			logging.error('Could not get human scimon file for {0} from {1}:{2}'.format(graceid,detector, str(e)))
	if (len(signoffdict) < len(detectors)):
		logging.info('Have not gotten all the human signoffs yet but not yet DQV')
		return 'Incomplete human signoff checks.'
	elif (len(signoffdict) > len(detectors)):
		logging.info('Too many human signoffs in signoff dictionary.')
	else:
		logging.info('Ready to run human signoff check for {0}'.format(graceid))
		if ('Fail' in signoffdict.values()):
			return 'Failed human signoff checks.'
		else:
			return 'Passed human signoff checks.'

#--------------------------------------------------------------------------------------
# Begin processing
#--------------------------------------------------------------------------------------
begintime = gpstime.gps_time_now()

# Create a dictionary from the LVAlert message contents and extract its info
streamdata = str(stdin.read())
streamdata = json.loads(streamdata) #json.loads turns string into dictionary

#outfile = open('tmp_for_gracedb.txt', 'a')
#outfile.write(str(streamdata))
#outfile.write('\n')
#outfile.write('\n')
#outfile.close()

alert_type = streamdata['alert_type']
graceid = streamdata['uid']
description = streamdata['description']
filename = streamdata['file']

#--------------------------------------------------------------------------------------
# Handle labeling events
#--------------------------------------------------------------------------------------
if alert_type == 'label':
	if description == 'PE_READY':
		# Fetch the event log list from the GraceDB server
		log_dicts = g.logs(graceid).json()['log']
		for message in log_dicts:
			if 'Last skymap submitted was' in message['comment']:
				skymapinfo = re.findall(r'Last skymap submitted was (\S+) type (\S+).', message['comment'])
				skymap_filename = skymapinfo[0][0]
				skymapname = re.findall(r'(\S+).fits', skymap_filename)[0]
				skymap_type = skymapname + '-' + skymapinfo[0][1]
				skymap_image_filename = skymapname + '.png'
				process_alert(g, graceid, 'update', '%s' % skymap_filename, '%s' % skymap_type, '%s' % skymap_image_filename)
				break
	elif description == 'EM_READY':
		logging.info('Submitting Initial VOEvent to GCN for event {0}'.format(graceid))
		# Fetch the event log list from the GraceDB server
		log_dicts = g.logs(graceid).json()['log']
		for message in log_dicts:
			if 'Last skymap submitted was' in message['comment']:
				skymapinfo = re.findall(r'Last skymap submitted was (\S+) type (\S+).', message['comment'])
				skymap_filename = skymapinfo[0][0]
				skymapname = re.findall(r'(\S+).fits', skymap_filename)[0]
				skymap_type = skymapname + '-' + skymapinfo[0][1]
				skymap_image_filename = skymapname + '.png'
				process_alert(g, graceid, 'initial', '%s' % skymap_filename, '%s' % skymap_type, '%s' % skymap_image_filename)
				break
	elif (description=='DQV' or description=='INJ'):
        # Check: Have we already sent out alerts on this event?
	# Look through the log messages to see if any VOEvents have been uploaded by gdb_processor
		log_dicts = g.logs(graceid).json()['log']
		for message in log_dicts:
			#XXX: After we connect with GCN, change to-- if 'Successfully sent VOEvent' in message['comment']:
			if 'VOEvent' in message['comment']:
				logging.info('Submitting Retraction VOEvent to GCN for event {0}'.format(graceid))
				process_alert(g, graceid, 'retraction')
			else:
				# This means that no previous VOEvent has been sent out before and therefore, no alert needs to be sent out
				pass

#--------------------------------------------------------------------------------------
# Handle new candidate event
#--------------------------------------------------------------------------------------
elif alert_type == 'new':
	logging.info('Got new event {0}'.format(graceid))
	# Get event information from streamdata
	event_dict = streamdata['object'] # This used to be-- event_dict = g.events(graceid).next()
	far = event_dict['far']
	pipeline = event_dict['pipeline']
	search = event_dict['search']
	labels = event_dict['labels']
	# Calculate the FAR threshold for this event
	farthresh = get_farthresh(pipeline, search)

	# if FAR is above threshold, or if event is labeled INJ or DQV, do not create alert
	# Also log message saying why no alert was created
	if far >= farthresh:
		logging.info('Rejected {0} due to large FAR'.format(graceid))
		r = g.writeLog(graceid, 'Candidate event rejected due to large FAR', tagname = 'em_follow')
	elif 'INJ' in labels:
		logging.info('Rejected {0} due to INJ label'.format(graceid))
		r = g.writeLog(graceid, 'Candidate event rejected due to INJ label', tagname = 'em_follow')
	elif 'DQV' in labels:
		logging.info('Rejected {0} due to DQV label'.format(graceid))
		r = g.writeLog(graceid, 'Candidate event rejected due to DQV label', tagname = 'em_follow')
	else:
		logging.info('Submitting Preliminary VOEvent to GCN for event {0}'.format(graceid))
		process_alert(g, graceid, 'preliminary')

#--------------------------------------------------------------------------------------
# Handle uploaded files
#--------------------------------------------------------------------------------------
elif alert_type=='update':
	# No need to continue processing if no file is present
	# This is the case for lvalert_listen alerts about new log messages for instance
	if len(filename)==0:
		exit()

	# Since we will also need information about the event itself, fetch the event dict
	try:
		event_dict = g.events(graceid).next()
	except Exception, e:
		logging.error('Could not fetch event information: {0}'.format(str(e)))
		exit()

	far = event_dict['far']
	pipeline = event_dict['pipeline']
	group = event_dict['group']
        search = event_dict['search']
	labels = event_dict['labels']
	detectors = str(event_dict['instruments']).split(',')
	farthresh = get_farthresh(pipeline, search)

	# First check FAR and labels
	if (far >= farthresh or 'INJ' in labels or 'DQV' in labels):
		logging.info('Ignoring update for {0} due to INJ, DQV, or high FAR'.format(graceid))
		exit()

	# Check whether the file in question is a skymap
	# We assume that any file with the .fits or .fits.gz extension *and* the 'sky_loc' tag will be a skymap
	# The tag names should also contain provenance information for the skymap, which could be useful here
	alert_dict = streamdata['object']

	#XXX Right now, 'sky_loc' tag does not appear under tag_names section of the alert that tips off lvalert_listen.
	#XXX Eventually change this to-- if (filename.endswith('.fits.gz') or filename.endswith('.fits')) and 'sky_loc' in tag_names:
	if (filename.endswith('.fits.gz') or filename.endswith('.fits')):
		# First, get the submitter name 
		skymap_filename = filename
		#skymap_type = alert_dict['issuer']['username']
		skymap_type = group + search
		r = g.writeLog(graceid, 'Last skymap submitted was {0} type {1}.'.format(skymap_filename, skymap_type), None, None, None)

		# If new skymaps are loaded, check if the event has passed iDQ checks by reading the log and labeling the event as either 'EM_READY' or 'PE_READY'
		#'EM_READY' is the label set if there have been no previous skymaps
		# 'PE_READY' is the label set if we've already sent out an Initial Localization VOEvent
		
		logging.info('Got skymap {0} for event {1}'.format(filename, graceid))

		# Fetch the event log list from the GraceDB server
		log_dicts = g.logs(graceid).json()['log']
		for message in log_dicts:
			if 'VOEvent of type initial_loc' in message['comment']:
				# Set label 'PE_READY' since the initial_localization alert was already sent out
				# It must already be labeled EM_READY
				logging.info('Labeling {0} with PE_READY'.format(graceid))
				r = g.writeLabel(graceid, 'PE_READY')
			elif 'Candidate event passed iDQ checks.' in message['comment']:
				if humanscimons=='yes':
					if checkSignoffs(graceid)=='Failed human signoff checks.':
						r = g.writeLog(graceid, 'Finished running human signoff checks. Candidate event failed human signoff checks.', 								None, None, 'em_follow')
						logging.info('Labeling {0} with DQV'.format(graceid))
						r = g.writeLabel(graceid, 'DQV')
						exit()
					elif checkSignoffs(graceid)=='Incomplete human signoff checks.':
						exit()
					elif checkSignoffs(graceid)=='Passed human signoff checks.':
						r = g.writeLog(graceid, 'Finished running human signoff checks. Candidate event passed human signoff checks.', 
							None, None, 'em_follow')
						logging.info('Labeling {0} with EM_READY'.format(graceid))
						r = g.writeLabel(graceid, 'EM_READY')
						# Break so that we only try applying this label once at most
						break
				else:
					logging.info('Labeling {0} with EM_READY'.format(graceid))
					r = g.writeLabel(graceid, 'EM_READY')
			else:
				# This means that our event did not pass the iDQ/human signoff checks, or the iDQ/human signoff checks are not finished yet
				# Thus we will apply the proper label when the iDQ/human signoff check finishes
				logging.info('No action taken on skymap for {0}'.format(graceid))

	# If the uploaded file is an iDQ file, start the iDQ check process
	if (filename.endswith('.txt') and 'idq' in filename):
		logging.info('Got iDQ file {0} for event {1}'.format(filename, graceid))		

		# Set up the idqvalue and joint_FAP_values dictonaries
		# These will store the minfap values & computed joint_FAP values from all of the detector sites for each pipeline
		idqvalues = {}
		joint_FAP_values={}
		timeseriesinfo = re.findall(r'-(.*?)-(.*?).txt', filename)
		mingpstime = timeseriesinfo[0][0]
		duration = timeseriesinfo[0][1]
		for pipeline in idq_pipelines:
			pipeline_values = []
			for detector in detectors:
				minfapfilename = '{0}_idq_{1}_summary_{2}_test-{3}-{4}.txt'.format(detector, pipeline, graceid, mingpstime, duration)
				try:
					idqfiletxt = g.files(graceid, minfapfilename)
					min_fap = re.findall(r'min_fap : (.*?)\n',idqfiletxt.read())
					min_fap = float(min_fap[0])
					detectorstring = '{0}.{1}'.format(pipeline, detector)
					idqvalues[detectorstring] = min_fap
					logging.info('Got the min_fap for {0} {1} using {2} is {3}'.format(detector, graceid, pipeline, min_fap))
				except:
					logging.info('Could not get minfap from {0} for {1} yet.'.format(detector, pipeline))
			# Now, even if you did not get all the minfap values for a specific pipeline, calculate the joint min-FAP thus far for each pipeline
			for key in idqvalues.keys():
				if pipeline in key:
					pipeline_values.append(idqvalues[key])
			joint_FAP_values[pipeline] = functools.reduce(operator.mul, pipeline_values, 1)
		if (len(idqvalues) < (len(idq_pipelines)*len(detectors))):
			logging.info('Have not gotten all the minfap values for {0} yet'.format(graceid))
			if (min(idqvalues.values() and joint_FAP_values.values()) < idqthresh):
				r = g.writeLog(graceid, 'Finished running iDQ checks. Candidate event rejected because incomplete joint min-FAP value already less than iDQ threshold.', tagname = 'em_follow')
				logging.info('iDQ check failed. Applying DQV label to event {0}'.format(graceid))
				r = g.writeLabel(graceid, 'DQV')
				exit()

		elif (len(idqvalues) > (len(idq_pipelines)*len(detectors))):
			logging.info('Too many minfap values in idqvalues dictionary for {0}'.format(graceid))
		else:
			logging.info('Ready to run idq_checks for {0}'.format(graceid))
			# First make sure that we haven't already run the checks -- we don't want to over-send alerts
			# Check log to see if we've said 'Finished running iDQ checks.'
			log_dicts = g.logs(graceid).json()['log']
			for message in log_dicts:
				if 'Finished running iDQ checks.' in message['comment']:
					exit()

			# Now that iDQ checks are finished, we want to know whether the event passed the iDQ checks or not.
			# If they don't pass the checks, we set the label 'DQV'
			# If they do pass the checks, we write a log message saying that they did
			# 'glitch-FAP' is the probability that the classifier thinks there was a glitch and *there was not a glitch*
			# 'glitch-FAP'-> 0 means high confidence there is a glitch
			# 'glitch-FAP'-> 1 means low confidence there is a glitch
			# What we want is something like the minimum of the products of FAPs from different sites computed for each classifier
			# Calculate joint_FAP values for all the iDQ pipelines
			for pipeline in idq_pipelines:
				joint_FAP = 1
				for detector in detectors:
					detectorstring = '{0}.{1}'.format(pipeline, detector)
					joint_FAP = joint_FAP*idqvalues[detectorstring]
				joint_FAP_values[pipeline] = joint_FAP
				logging.info('Got joint_FAP = {0} for event {1} iDQ pipeline {2}'.format(joint_FAP, graceid, pipeline))
			if min(joint_FAP_values.values()) > idqthresh:
				logging.info('Event {0} passed iDQ check.'.format(graceid))
				r = g.writeLog(graceid, "Finished running iDQ checks. Candidate event passed iDQ checks.", None, None, "em_follow")
				if humanscimons=='yes': 
					if checkSignoffs(graceid)=='Failed human signoff checks.':
						r = g.writeLog(graceid, "Finished running human signoff checks. Candidate event failed human signoff checks.", None, 								None, "em_follow")
						r = g.writeLabel(graceid, 'DQV')
						exit()
					elif checkSignoffs(graceid)=='Incomplete human signoff checks.':
						exit()
					elif checkSignoffs(graceid)=='Passed human signoff checks.':
						r = g.writeLog(graceid, "Finished running human signoff checks. Candidate event passed human signoff checks.", None, 								None, "em_follow")
						pass
				elif humanscimons!='yes':
					pass
				# Check log to see if there is a skymap file or not... If so, set label 'EM_READY'
				for message in log_dicts:
					#XXX Need to generalize this since not all messages say 'skymap created'
					if 'skymap created' in message['comment']: 
						logging.info('Applying EM_READY label to event {0}'.format(graceid))
						r = g.writeLabel(graceid, 'EM_READY')
						break
			else:
				r = g.writeLog(graceid, 'Finished running iDQ checks. Candidate event rejected due to low iDQ FAP value of {0}'.format(joint_FAP), 						tagname = 'em_follow')
				logging.info('iDQ check failed. Applying DQV label to event {0}'.format(graceid))
				r = g.writeLabel(graceid, 'DQV')

	# If the uploaded file is a human signoff file, start the human signoff check process if necessary
	if alert_type =='update' and (filename.endswith('.txt') and ('signoff' in filename)):
		if humanscimons=='yes':
			if checkSignoffs(graceid)=='Failed human signoff checks.':
				r = g.writeLog(graceid, "Finished running human signoff checks. Candidate event failed human signoff checks.", None, None, "em_follow")
				logging.info('Human signoff check failed. Applying DQV label to event {0}'.format(graceid))
				r = g.writeLabel(graceid, 'DQV')
				exit()
			elif checkSignoffs(graceid)=='Incomplete human signoff checks.':
				exit()
			elif checkSignoffs(graceid)=='Passed human signoff checks.':
				r = g.writeLog(graceid, "Finished running human signoff checks. Candidate event passed human signoff checks.", None, None, "em_follow")
				pass
		elif humanscimons!='yes':
			pass
		log_dicts = g.logs(graceid).json()['log']
		for message in log_dicts:
			if 'Candidate event passed iDQ checks.' in message['comment']:
				for message in log_dicts:
					if 'skymap created' in message['comment']: #XXX Need to generalize this since not all messages say 'skymap created'
						logging.info('Labeling {0} with EM_READY'.format(graceid))
						r = g.writeLabel(graceid, 'EM_READY')
						break
					else: # This means that no skymap was loaded so we need to wait for the map before the EM_READY label is set.
						pass
			else:
				pass

#--------------------------------------------------------------------------------------
# Handle unknown alert type
#--------------------------------------------------------------------------------------
else:
	# GraceDB gave us a strange alert type.
	logging.error('Alert type %s unrecognized. Quitting'.format(alert_type))
	exit()

#--------------------------------------------------------------------------------------
# Wrap up
#--------------------------------------------------------------------------------------
endtime = gpstime.gps_time_now()
processtime = endtime - begintime
logging.info('Process time: {0} s'.format(processtime))
