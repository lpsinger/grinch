#!/usr/bin/env python
import os
import json
from sys import stdin
from ligo.gracedb.rest import GraceDb, HTTPError
import re
import ConfigParser
from lal import gpstime
import time
import datetime
import urllib

import logging

from grinch.approval_utils import get_farthresh, get_idqthresh, process_alert, checkSignoffs 
from grinch.approval_utils import checkLabels, checkIdqStatus, getIdqAndJointFapValues
from grinch.workflow_helper import home

# Activate a virtualenv in order to be able to use Comet.
VIRTUALENV_ACTIVATOR = "/home/gracedb.processor/users/bstephens/cometenv/bin/activate_this.py"
execfile(VIRTUALENV_ACTIVATOR, dict(__file__=VIRTUALENV_ACTIVATOR))

#-------------------------------------------------------------------------------------
# Fetch parameters
#--------------------------------------------------------------------------------------
# Import FAR threshold, iDQ threshold, etc from config file
config = ConfigParser.SafeConfigParser()
etc = home + '/opt/etc/'
config.read(etc + 'approval_processor_config.ini')
ignore_idq = config.get('default', 'ignore_idq')
idq_pipelines = config.get('default', 'idq_pipelines')
idq_pipelines = idq_pipelines.replace(' ','') # remove any spaces
idq_pipelines = idq_pipelines.split(',') # a list of iDQ pipelines
hardware_inj = config.get('default', 'hardware_inj')
humanscimons = config.get('default', 'humanscimons')

# Import list of skymap submitters to ignore
skymap_ignore_list = config.get('default', 'skymap_ignore_list')

# Set up logging
logger = logging.getLogger('approval_processor')
logging_filehandler = logging.FileHandler(config.get('default', 'approval_processor_logfile'))
logging_filehandler.setLevel(logging.INFO)
logger.setLevel(logging.INFO)
logger.addHandler(logging_filehandler)
ts = time.time()
st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d %H:%M:%S')

# A common set of tasks related to human signoffs
def passesHumanSignoffsOrExit(client, logger, graceid, detectors):
   	signoffResult = checkSignoffs(client, logger, graceid, detectors)
   	if signoffResult=='Fail':
        	msg = 'AP: Finished running human signoff checks. Candidate event failed human signoff checks.'
        	r = client.writeLog(graceid, msg, tagname='em_follow')
        	logger.info('{0} -- {1} -- Labeling with DQV.'.format(st, graceid))
        	r = client.writeLabel(graceid, 'DQV')
        	exit()
	elif signoffResult=='Pass':
        	msg = 'AP: Finished running human signoff checks. Candidate event passed human signoff checks.'
        	r = client.writeLog(graceid, msg, tagname='em_follow')
	else:
        	logger.info('{0} -- {1} -- No action taken due to scimon status.'.format(st, graceid))
        	exit()

#--------------------------------------------------------------------------------------
# Begin processing
#--------------------------------------------------------------------------------------
# Create a dictionary from the LVAlert message contents and extract its info
streamdata = str(stdin.read())
streamdata = json.loads(streamdata) #json.loads turns string into dictionary

alert_type = streamdata['alert_type']
graceid = streamdata['uid']
description = streamdata['description']
filename = streamdata['file']

# Instantiate the GraceDB client
# For testing purposes, this is pointed towards simdb.
# If we leave out the argument, it will default to https://gracedb.ligo.org/api/
try:
	#g = GraceDb('https://moe.phys.uwm.edu/branson/api/')
	g = GraceDb()
except Exception, e:
	logger.error('{0} -- {1} -- Connection to GraceDB failed: {2}.'.format(st, graceid, str(e)))
	exit()

begintime = gpstime.gps_time_now()

# XXX If the graceid starts with 'M' for MDCs or 'S' for Simulation, we want to ignore the event.
if re.match('M', graceid) or re.match('S', graceid):
	logger.error('{0} -- {1} -- Mock data challenge or simulation. Quitting.'.format(st, graceid))
	exit()

#--------------------------------------------------------------------------------------
# Handle labeling events
#--------------------------------------------------------------------------------------
if alert_type == 'label':
	# Since we will need information about the event itself, fetch the event dict
	try:
		event_dict = g.events(graceid).next()
	except Exception, e:
		logger.error('{0} -- {1} -- Connection to GraceDB failed: {2}.'.format(st, graceid, str(e)))
		exit()

	far = event_dict['far']
	pipeline = event_dict['pipeline']
	if 'search' in event_dict.keys():
		search = event_dict['search']
	else:
		search = ''
	labels = event_dict['labels']
	group = event_dict['group']
	detectors = str(event_dict['instruments']).split(',')
	farthresh = get_farthresh(config, pipeline, search)

	# First check FAR
	if far >= farthresh:
		logger.info('{0} -- {1} -- Ignoring update due to high FAR.'.format(st, graceid))
		exit()

	if description == 'PE_READY':
		logger.info('{0} -- {1} -- Submitting update VOEvent to GCN.'.format(st, graceid))
		# Fetch the event log list from the GraceDB server
		log_dicts = g.logs(graceid).json()['log']
		for message in reversed(log_dicts): # reversed pulls the most recent skymap to reference in the VOEvent
			if 'Last skymap submitted was' in message['comment']:
				skymapinfo = re.findall(r'Last skymap submitted was (.*) type (.*) by (.*).', message['comment'])
				skymap_filename = skymapinfo[0][0]
				skymapname = re.findall(r'(\S+).fits', skymap_filename)[0]
				skymap_type = skymapname + '-' + skymapinfo[0][1]
				skymap_image_filename = skymapname + '.png'
				submitter = skymapinfo[0][2]
				if submitter in skymap_ignore_list:
					pass
				else:
					process_alert(g, logger, graceid, 'update', skymap_filename, skymap_type, skymap_image_filename)
					break
	elif description == 'EM_READY':
		logger.info('{0} -- {1} -- Submitting initial VOEvent to GCN.'.format(st, graceid))
		# Fetch the event log list from the GraceDB server
		log_dicts = g.logs(graceid).json()['log']
		for message in reversed(log_dicts):
			if 'Last skymap submitted was' in message['comment']:
				skymapinfo = re.findall(r'Last skymap submitted was (.*) type (.*) by (.*).', message['comment'])
				skymap_filename = skymapinfo[0][0]
				skymapname = re.findall(r'(\S+).fits', skymap_filename)[0]
				skymap_type = skymapname + '-' + skymapinfo[0][1]
				skymap_image_filename = skymapname + '.png'
				submitter = skymapinfo[0][2]
				if submitter in skymap_ignore_list:
					pass
				else:
					process_alert(g, logger, graceid, 'initial', skymap_filename, skymap_type, skymap_image_filename)
					break
	elif (checkLabels(hardware_inj, description.split()) > 0):
        # Check: Have we already sent out alerts on this event?
		voevent_dicts = g.voevents(graceid).json()['voevents']
		if len(voevent_dicts):
			for voevent in voevent_dicts:
				if voevent['voevent_type'] == 'RE':
					# We have already sent a retraction.
					# Thus, no action is necessary.
					exit()
			# There are existing VOEvents, but we haven't already sent a 
			# retraction, so let's do that.
			process_alert(g, logger, graceid, 'retraction')

#--------------------------------------------------------------------------------------
# Handle new candidate event
#--------------------------------------------------------------------------------------
elif alert_type == 'new':
	logger.info('{0} -- {1} -- Got new event.'.format(st, graceid))
	# Get event information from streamdata
	event_dict = streamdata['object']
	far = event_dict['far']
	pipeline = event_dict['pipeline']
	labels = event_dict['labels']
	event_time = float(event_dict['gpstime'])
	if 'search' in event_dict.keys():
		search = event_dict['search']
	else:
		search = ''
	# Calculate the FAR threshold for this event
	farthresh = get_farthresh(config, pipeline, search)

	# If FAR is above threshold, or if event is labeled INJ or DQV, do not create alert
	# Also log message saying why no alert was created
	if far >= farthresh:
		logger.info('{0} -- {1} -- Rejected due to large FAR. {2} >= {3}'.format(st, graceid, far, farthresh))
		r = g.writeLog(graceid, 'AP: Candidate event rejected due to large FAR. {0} >= {1}'.format(far, farthresh), tagname = 'em_follow')
	elif checkLabels(hardware_inj, labels.keys()) > 0:
		logger.info('{0} -- {1} -- Ignoring new event due to INJ or DQV.'.format(st, graceid))
		r = g.writeLog(graceid, 'AP: Candidate event rejected due to INJ or DQV label.', tagname = 'em_follow')
	else:
		# Need to check whether there's a Hardware Injection found +/-2 seconds of this event gpstime
		from raven.search import query
		tl = -2
		th = 2
		Injections = query('HardwareInjection', event_time, tl, th)
		if len(Injections) > 0:
			if hardware_inj=='no':
				logger.info('{0} -- {1} -- Ignoring new event because we found hardware injection.'.format(st, graceid))
				r = g.writeLog(graceid, 'AP: Candidate event rejected because we found hardware injection.', tagname = 'em_follow')
				logger.info('{0} -- {1} -- Labeling with INJ.'.format(st, graceid))
				r = g.writeLabel(graceid, 'INJ')
				exit()
			else:
				pass
		elif len(Injections)==0:
			pass
		r = g.writeLog(graceid, 'AP: Candidate event has low enough FAR. {0} < {1}'.format(far, farthresh), tagname = 'em_follow')		
		logger.info('{0} -- {1} -- Submitting preliminary VOEvent to GCN.'.format(st, graceid))
		process_alert(g, logger, graceid, 'preliminary')
		detectors = str(event_dict['instruments']).split(',')
		for detector in detectors:
			logger.info('{0} -- {1} -- Labeling with {2}OPS.'.format(st, graceid, detector))
			r = g.writeLabel(graceid, '{0}OPS'.format(detector))
		# Expose event to LV-EM
		url_perm_base = g.service_url + urllib.quote('events/{0}/perms/gw-astronomy:LV-EM/'.format(graceid))
		for perm in ['view', 'change']:
			url = url_perm_base + perm
			r = g.put(url)

#--------------------------------------------------------------------------------------
# Handle uploaded files
#--------------------------------------------------------------------------------------
elif alert_type=='update':
	# Since we will need information about the event itself, fetch the event dict
	try:
		event_dict = g.events(graceid).next()
	except Exception, e:
		logger.error('{0} -- {1} -- Connection to GraceDB failed: {2}.'.format(st, graceid, str(e)))
		exit()

	far = event_dict['far']
	pipeline = event_dict['pipeline']
	if 'search' in event_dict.keys():
		search = event_dict['search']
	else:
		search = ''
	labels = event_dict['labels']
	group = event_dict['group']
	detectors = str(event_dict['instruments']).split(',')
	farthresh = get_farthresh(config, pipeline, search)

	# First check FAR and labels
	if (far >= farthresh or (checkLabels(hardware_inj, labels.keys()) > 0)):
		logger.info('{0} -- {1} -- Ignoring update due to INJ, DQV, or high FAR.'.format(st, graceid))
		exit()

	# Determine the value of use_idq depending on the event group
	if group in ignore_idq:
		use_idq = 'no'
	else:
		use_idq = 'yes'
		idqthresh = get_idqthresh(config, pipeline, search)

	# Check whether the file in question is a skymap
	# We assume that any file with the .fits or .fits.gz extension *and* the 'sky_loc' tag will be a skymap
	# The tag names should also contain provenance information for the skymap, which could be useful here

	#XXX Right now, 'sky_loc' tag does not appear under tag_names section of the alert that tips off lvalert_listen.
	#XXX Eventually change this to-- if (filename.endswith('.fits.gz') or filename.endswith('.fits')) and 'sky_loc' in tag_names:
	if (filename.endswith('.fits.gz') or filename.endswith('.fits')):
		# First, get the submitter name 
		skymap_filename = filename
		skymap_type = group + search
		display_name = streamdata['object']['issuer']['display_name']
		msg = 'AP: Last skymap submitted was {0} type {1} by {2}.'.format(skymap_filename, skymap_type, display_name)
		r = g.writeLog(graceid, msg.replace('  ',' '))

		if display_name in skymap_ignore_list:
			exit()
		else:
			pass
		
		# If new skymaps are loaded, check if the event has passed iDQ checks by reading the log and labeling the event as either 'EM_READY' or 'PE_READY'
		#'EM_READY' is the label set if there have been no previous skymaps
		# 'PE_READY' is the label set if we've already sent out an Initial Localization VOEvent
		
		logger.info('{0} -- {1} -- Got skymap {2}.'.format(st, graceid, filename))

		voevent_dicts = g.voevents(graceid).json()['voevents']
		if len(voevent_dicts):
			latest_voevent = voevent_dicts[-1] 
			latest_voevent_type = latest_voevent['voevent_type']
			if latest_voevent_type == 'UP': 
				skymapname = re.findall(r'(\S+).fits', skymap_filename)[0]
				skymap_image_filename = skymapname + '.png'
				process_alert(g, logger, graceid, 'update', skymap_filename, skymap_type, skymap_image_filename)
			elif latest_voevent_type == 'IN':
				# Set label 'PE_READY' since the initial_localization alert was already created and/or sent out
				# It must already be labeled EM_READY
				logger.info('{0} -- {1} -- Labeling with PE_READY.'.format(st, graceid))
				r = g.writeLabel(graceid, 'PE_READY')
			elif latest_voevent_type == 'PR':
				# XXX Note: this assumes that there has been at least a Preliminary VOEvent.
				# We want to apply the EM_READY label as long as the event passes iDQ and 	
				# human scimon checks (if necessary)
				if use_idq=='yes':
					if not checkIdqStatus(g, graceid)=='Pass':
						logger.info('{0} -- {1} -- No action taken on skymap due to iDQ status'.format(st, graceid))
						exit()

				if humanscimons=='yes':
					passesHumanSignoffsOrExit(g, logger, graceid, detectors)

				# If we're still here, we are ready to apply the EM_READY label
				logger.info('{0} -- {1} -- Labeling with EM_READY.'.format(st, graceid))
				r = g.writeLabel(graceid, 'EM_READY')

	# Log comments have no files attached but could still contain iDQ information
	if len(filename)==0:
		comment = streamdata['object']['comment']
		if not re.match('minimum glitch-FAP', comment):
			exit()
		elif use_idq=='yes':
			idqvalues, joint_FAP_values = getIdqAndJointFapValues(idq_pipelines, g, logger, graceid)

			if (len(idqvalues) < (len(idq_pipelines)*len(detectors))):
				logger.info('{0} -- {1} -- Have not gotten all the minfap values yet.'.format(st, graceid))
				if (min(idqvalues.values() and joint_FAP_values.values()) < idqthresh):
					r = g.writeLog(graceid, 'AP: Finished running iDQ checks. Candidate event rejected because incomplete joint min-FAP value already less than iDQ threshold. {0} < {1}'.format(min(idqvalues.values() and joint_FAP_values.values()), idqthresh), tagname = 'em_follow')
					logger.info('{0} -- {1} -- iDQ check failed. Labeling with DQV.'.format(st, graceid))
					r = g.writeLabel(graceid, 'DQV')
					exit()

			elif (len(idqvalues) > (len(idq_pipelines)*len(detectors))):
				logger.info('{0} -- {1} -- Too many minfap values in idqvalues dictionary.'.format(st, graceid))
			else:
				logger.info('{0} -- {1} -- Ready to run idq_checks.'.format(st, graceid))
				# First make sure that we haven't already run the checks -- we don't want to over-send alerts
				# Check log to see if we've said 'Finished running iDQ checks.'
				log_dicts = g.logs(graceid).json()['log']
				for message in log_dicts:
					if 'Finished running iDQ checks.' in message['comment']:
						exit()

				# Now that iDQ checks are finished, we want to know whether the event passed the iDQ checks or not.
				# If they don't pass the checks, we set the label 'DQV'
				# If they do pass the checks, we write a log message saying that they did
				# 'glitch-FAP' is the probability that the classifier thinks there was a glitch and *there was not a glitch*
				# 'glitch-FAP' -> 0 means high confidence there is a glitch
				# 'glitch-FAP' -> 1 means low confidence there is a glitch
				# What we want is something like the minimum of the products of FAPS from different sites computed for each classifier
				# Calculate the joint_FAP values for all the iDQ pipelines
				for pipeline in idq_pipelines:
					joint_FAP = 1
					for detector in detectors:
						detectorstring = '{0}.{1}'.format(pipeline, detector)
						joint_FAP = joint_FAP*idqvalues[detectorstring]
					joint_FAP_values[pipeline] = joint_FAP
					logger.info('{0} -- {1} -- Got joint_FAP = {2} for iDQ pipeline {3}.'.format(st, graceid, joint_FAP, pipeline))

				if min(joint_FAP_values.values()) > idqthresh:
					logger.info('{0} -- {1} -- Passed iDQ check.'.format(st, graceid))
					r = g.writeLog(graceid, 'AP: Finished running iDQ checks. Candidate event passed iDQ checks. {0} > {1}'.format(min(joint_FAP_values.values()), idqthresh), tagname='em_follow')
					if humanscimons=='yes':
						passesHumanSignoffsOrExit(g, logger, graceid, detectors)

					# Check log to see if there is a skymap file or not... If so, set label 'EM_READY'
					for message in log_dicts:
						if 'Last skymap submitted was' in message['comment']:
							logger.info('{0} -- {1} -- Labeling with EM_READY.'.format(st, graceid))
							r = g.writeLabel(graceid, 'EM_READY')
							break
				else:
					r = g.writeLog(graceid, 'AP: Finished running iDQ checks. Candidate event rejected due to low iDQ FAP value. {0} < {1}'.format(min(joint_FAP_values.values()), idqthresh), tagname = 'em_follow')
					logger.info('{0} -- {1} -- iDQ check failed. Labeling with DQV.'.format(st, graceid))
					r = g.writeLabel(graceid, 'DQV')

#--------------------------------------------------------------------------------------
# Handle human scimon signoffs
#--------------------------------------------------------------------------------------
elif alert_type=='signoff':
	# Since we will need information about the event itself, fetch the event dict
	try:
		event_dict = g.events(graceid).next()
	except Exception, e:
		logger.error('{0} -- {1} -- Connection to GraceDB failed: {2}.'.format(st, graceid, str(e)))
		exit()

	far = event_dict['far']
	pipeline = event_dict['pipeline']
	if 'search' in event_dict.keys():
		search = event_dict['search']
	else:
		search = ''
	labels = event_dict['labels']
	group = event_dict['group']
	farthresh = get_farthresh(config, pipeline, search)

	# First check FAR and labels
	if (far >= farthresh or (checkLabels(hardware_inj, labels.keys()) > 0)):
		logger.info('{0} -- {1} -- Ignoring update due to INJ, DQV, or high FAR.'.format(st, graceid))
		exit()

	# Determine the value of use_idq depending on the event group
	if group in ignore_idq:
		use_idq = 'no'
	else:
		use_idq = 'yes'
		idqthresh = get_idqthresh(config, pipeline, search)

	signoff_object = streamdata['object']
	instrument = signoff_object['instrument']
	# Get the status, 'OK' means 'okay' and 'NO' means 'not okay'
	status = signoff_object['status']

	if humanscimons=='yes':
		# Since we need to check the response from all detector sites, get the list of detectors for event
		detectors = str(event_dict['instruments']).split(',')
		passesHumanSignoffsOrExit(g, logger, graceid, detectors)
	elif humanscimons!='yes':
		if status=='NO':
			msg = 'AP: Candidate event failed human signoff checks.'
        		r = g.writeLog(graceid, msg, tagname='em_follow')
        		logger.info('{0} -- {1} -- Labeling with DQV.'.format(st, graceid))
        		r = g.writeLabel(graceid, 'DQV')
       			exit()
		else:
			pass

	log_dicts = g.logs(graceid).json()['log']
	for message in log_dicts:
		if 'Last skymap submited was' in message['comment']:
			for msg in log_dicts:
				if use_idq=='yes':
					if 'Candidate event passed iDQ checks' in msg['comment']: 
						logger.info('{0} -- {1} -- Labeling with EM_READY.'.format(st, graceid))
						r = g.writeLabel(graceid, 'EM_READY')
						break
					else:
						pass
				else:
					logger.info('{0} -- {1} -- Labeling with EM_READY.'.format(st, graceid))
					r = g.writeLabel(graceid, 'EM_READY')
					break
		else: # This means that no skymap was loaded so we need to wait for the map before the EM_READY label is set
			pass

#--------------------------------------------------------------------------------------
# Handle unknown alert type
#--------------------------------------------------------------------------------------
else:
	# GraceDB gave us a strange alert type.
	logger.error('{0} -- {1} -- Alert type {2} unrecognized. Quitting'.format(st, graceid, alert_type))
	exit()

#--------------------------------------------------------------------------------------
# Wrap up
#--------------------------------------------------------------------------------------
endtime = gpstime.gps_time_now()
processtime = endtime - begintime
#logger.info('{0} -- {1} -- Process time: {2} s.'.format(st, graceid, processtime))
