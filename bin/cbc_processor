#!/usr/bin/python


# Imports.
import os
import os.path
import subprocess
import tempfile
import re
import json
import ConfigParser

from sys             import exit, stdin
from ligo.gracedb.rest import GraceDb
from grinch.workflow_helper import directory, home
from glue.ligolw     import ligolw
from glue.ligolw     import utils


# Create a dictionary from the gracedb table.
streamdata = json.loads( stdin.read() )


# Read cbc_config.ini.
cp = ConfigParser.ConfigParser()
etc = home + '/opt/etc/'
cp.read( etc + 'cbc_config.ini' )

#dqwaitscript       = cp.get('executable', 'dqwaitscript')
#dqtolabelscript    = cp.get('executable', 'dqtolabelscript')
#coincdetscript     = cp.get('executable', 'coincdetscript')
gracedbcommand     = cp.get('executable', 'gracedbcommand')
coinc_search       = cp.get('executable', 'coincscript')
#vetodefinerfile    = cp.get('veto', 'vetodefinerfile')


# Build and move to a unique working directory.
working = directory(streamdata['uid'])
working.build_and_move()
wdir = working.name


## Check if the incoming event is new.
#if streamdata['alert_type'] == 'new':
#    pass
# Avoid race conditions by demanding that the file 'psd.xml.gz' exist before proceeding.
if streamdata['alert_type'] == 'update' and streamdata['file'] == 'psd.xml.gz':
	pass

# If the update is a .fits file, plot the all-sky map it contains.
elif streamdata['alert_type'] == 'update' and ( streamdata['file'].endswith('.fits') or streamdata['file'].endswith('.fits.gz') ):
	fitsfile = streamdata['file']
	plotfile = '%s.png' % fitsfile.split('.')[0]

	# Write plot_allsky.sub.
	contents = """\
universe            = local

executable          = /usr/bin/env
arguments           = " bayestar_plot_allsky -o %(directory)s/%(plot)s --colormap=OrRd %(directory)s/%(fits)s "
getenv              = True
notification        = never
accounting_group = ligo.prod.o1.cbc.pe.bayestar
accounting_group_user = alexander.urban

error               = %(directory)s/allsky_%(uid)s.err
output              = %(directory)s/allsky_%(uid)s.out

+LVAlertListen      = %(uid)s_plot_allsky

Queue
"""
	with open('plot_allsky.sub', 'w') as f:
		f.write(contents%{'fits':fitsfile, 'plot':plotfile, 'directory':wdir, 'uid':streamdata['uid']})

#	# Write plot_inj.sub.
#	contents   = """\
#universe            = local
#
#executable          = /usr/bin/env
#arguments           = " unblind_inj_search --graceid %(uid)s --sky-map %(directory)s/%(fits)s"
#getenv              = True
#notification        = never
#
#error               = %(directory)s/plot_inj_%(uid)s.err
#output              = %(directory)s/plot_inj_%(uid)s.out
#
#+LVAlertListen      = %(uid)s_plot_inj
#
#Queue
#"""
#	with open('plot_inj.sub', 'w') as f:
#		f.write(contents%{'fits':fitsfile, 'directory':wdir, 'uid': streamdata['uid']})

	# Write coinc_search_with_sky_map.sub.
	contents = """\
universe            = local

executable          = %(script)s
arguments           = " -g %(uid)s -t gw -w -1 5 -w -60 600 -s %(directory)s/%(fits)s "
getenv              = True
notification        = never
accounting_group = ligo.prod.o1.cbc.grb.raven
accounting_group_user = alexander.urban

output              = %(directory)s/coinc_search_%(uid)s.out
error               = %(directory)s/coinc_search_%(uid)s.error

+LVAlertListen      = %(uid)s_coinc_search

Queue
"""
	with open('coinc_search_with_sky_map.sub', 'w') as f:
		f.write(contents%{'script': coinc_search, 'directory': wdir, 'fits': fitsfile, 'uid': streamdata['uid']})


	# Write and submit fits_followup.dag.
	contents = """\
JOB PLOTALLSKY plot_allsky.sub
SCRIPT PRE PLOTALLSKY %(gracedbcommand)s download %(uid)s %(fits)s
SCRIPT POST PLOTALLSKY %(gracedbcommand)s --tag-name=sky_loc upload %(uid)s %(plot)s

#JOB COINCSEARCH coinc_search_with_sky_map.sub
#SCRIPT PRE COINCSEARCH %(gracedbcommand)s download %(uid)s %(fits)s

#PARENT COINCSEARCH CHILD PLOTALLSKY
"""
	with tempfile.NamedTemporaryFile(mode='w', suffix='.dag', prefix='fits_followup_', dir='.', delete=False) as dagfile:
		dagfilename = dagfile.name
		print >>dagfile, contents%{'gracedbcommand': gracedbcommand, 'uid': streamdata['uid'], 'fits': fitsfile, 'plot': plotfile}

	# Create a uniquely-named log file.
	logfid, logpath = tempfile.mkstemp(suffix='.nodes.log', prefix=streamdata['uid'])

	# Set environment variable telling condor to use this log file
	# for communication with nodes.
	os.environ['_CONDOR_DAGMAN_DEFAULT_NODE_LOG'] = logpath

	# Submit the processor dag.
	condorargs=['condor_submit_dag', dagfilename]
	os.execlp('condor_submit_dag', *condorargs)

# Elsewise, end the processor.
else:
	exit()


## Get ifo info.
#gpstime  = coinctable[0].end_time
#ifonames = ['H1','L1','V1']
#if 'test' in cp.sections():
#	ifos = cp.get('test','ifos')
#else:
#	ifos = coinctable[0].ifos
#
#disable_ifos = [ifo for ifo in ifonames if ifo not in ifos]
#itime        = str( int( float(gpstime) + 0.5 ) )


##############################
## PRODUCE CONDOR SUB FILES ##
##############################

# Write data quality.sub.
#contents   = """\
#universe            = local
#
#executable          = /bin/cp
#arguments           = /home/gdb_processor/dq-fake.xml %(directory)s/dq.xml
#getenv              = True
#notification        = never
#
#output              = %(directory)s/dq_%(uid)s.out
#error               = %(directory)s/dq_%(uid)s.error
#
#+LVAlertListen      = %(uid)s_dq
#Queue
#"""
#with open('dq.sub', 'w') as f:
#	f.write(contents%{'directory': wdir, 'uid': streamdata['uid']})
#
#	f.write(contents%{'script': dqtolabelscript, 'gdbcommand': gracedbcommand, 'vetodefinerfile': vetodefinerfile, 'directory': wdir, 'uid': streamdata['uid']})

# Write emlabel.sub.
#contents   = """\
#universe            = local
#
#executable          = %(gracedbcommand)s
#arguments           = " label %(uid)s EM_READY "
#getenv              = True
#notification        = never
#
#error               = %(directory)s/emlabel_%(uid)s.err
#output              = %(directory)s/emlabel_%(uid)s.out
#
#+LVAlertListen      = %(uid)s_emlabel
#Queue
#"""
#with open('emlabel.sub', 'w') as f:
#	f.write(contents%{'gracedbcommand': gracedbcommand, 'directory': wdir, 'uid': streamdata['uid']})

# Write localize.sub.
contents   = """\
universe            = local

executable          = /usr/bin/env
environment         = OMP_NUM_THREADS=32
request_memory      = 1400 MB
arguments           = " bayestar_localize_lvalert %(uid)s "
getenv              = True
notification        = never
accounting_group = ligo.prod.o1.cbc.pe.bayestar
accounting_group_user = alexander.urban

error               = %(directory)s/localize_%(uid)s.err
output              = %(directory)s/localize_%(uid)s.out

+LVAlertListen      = %(uid)s_localize

Queue
"""
with open('localize.sub', 'w') as f:
	f.write(contents%{'directory': wdir, 'uid': streamdata['uid']})

# Write coinc_search.sub.
contents = """\
universe            = local

executable          = %(script)s
arguments           = " -g %(uid)s -t gw -w -1 5 -w -60 600 "
getenv              = True
notification        = never
accounting_group = ligo.prod.o1.cbc.grb.raven
accounting_group_user = alexander.urban

output              = %(directory)s/coinc_search_%(uid)s.out
error               = %(directory)s/coinc_search_%(uid)s.error

+LVAlertListen      = %(uid)s_coinc_search

Queue
"""
with open('coinc_search.sub', 'w') as f:
    f.write(contents%{'script': coinc_search, 'directory': wdir, 'uid': streamdata['uid']})

## Write find_inj.sub.
#contents   = """\
#universe            = local
#
#executable          = /usr/bin/env
#arguments           = " unblind_inj_search --graceid %(uid)s --label 1"
#getenv              = True
#notification        = never
#
#error               = %(directory)s/find_inj_%(uid)s.err
#output              = %(directory)s/find_inj_%(uid)s.out
#
#+LVAlertListen      = %(uid)s_find_inj
#
#Queue
#"""
#with open('find_inj.sub', 'w') as f:
#	f.write(contents%{'directory':wdir, 'uid': streamdata['uid']})

## Write find_data.sub.
#contents   = """\
#universe            = local
#
#executable          = /usr/bin/env
#arguments           = " find_data --padding 20 -g %(uid)s -f H1=H1_ER_C00_L1 -f L1=L1_ER_C00_L1 -f V1=V1Online -s ldr.ligo.caltech.edu:443 --verbose "
#getenv              = True
#notification        = never
#
#error               = %(directory)s/find_data_%(uid)s.err
#output              = %(directory)s/find_data_%(uid)s.out
#
#+LVAlertListen      = %(uid)s_find_data
#
#Queue
#"""
#with open('find_data.sub', 'w') as f:
#	f.write(contents%{'directory': wdir, 'uid': streamdata['uid']})


#################################
## WRITE CONDOR DAG AND SUBMIT ##
#################################

# Write cbc_runner.dag.
contents = """\
JOB LOCALIZE localize.sub

JOB COINCSEARCH coinc_search.sub
"""
with open('cbc_runner.dag', 'w') as f:
	f.write(contents % {'gracedbcommand': gracedbcommand, 'uid': streamdata['uid']})

# Create a uniquely-named log file.
logfid, logpath = tempfile.mkstemp(suffix='.nodes.log', prefix=streamdata['uid'])

# Set environment variable telling condor to use this log file
# for communication with nodes.
os.environ['_CONDOR_DAGMAN_DEFAULT_NODE_LOG'] = logpath

# Submit the processor dag.
condorargs=['condor_submit_dag','cbc_runner.dag']
#os.execlp('condor_submit_dag', *condorargs)
subprocess.call(condorargs)


if cp.has_section('lalinference'):
	print "Starting LALInference follow-up"
	far_threshold = cp.get('lalinference', 'far_threshold')
	gracedb = GraceDb()  # Initialize instance of GraceDB client
	far = list(gracedb.events( streamdata['uid'] ))[0]['far']
	if far <= eval(far_threshold):
		print "FAR low enough"
		lscsoftrc = cp.get('lalinference', 'lscsoftrc')
		command = ['bash', '-c', 'source '+lscsoftrc+' && env']
		proc = subprocess.Popen(command, stdout = subprocess.PIPE)
		saved_key=''
		for line in proc.stdout:
			(key, sep, value) = line.partition("=")
			if sep=='':
				os.environ[saved_key]=os.environ[saved_key]+'\n'+key.rstrip()
			else:
				os.environ[key] = value.rstrip()
			saved_key=key
		proc.communicate()
		lalinference_inifile = cp.get('lalinference', 'inifile')
		lalinferenceargs = [ 'lalinference_pipe'
				     , '--run-path'
				     , wdir+'/lalinference/'+lalinference_inifile.split('/')[-1].strip('.ini')
				     , '--gid'
				     , streamdata['uid']
				     , '--daglog-path'
				     , '/usr1/'+os.environ['USER']
				     , lalinference_inifile
				     #, '--dax'
				     #, '--grid-site'
				     #, 'local'
				     #, '--pegasus-submit'
				     , '--condor-submit'
				     ]
		subprocess.call(lalinferenceargs)
	else:
		print "FAR is higher than %s; not triggering LALInference for event %s." % (eval(far_threshold), streamdata['uid'])
